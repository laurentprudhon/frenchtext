{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download wikipedia and extract one text file per article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastai : Jeremy Howard / Sylvain Gugger\n",
    "# https://github.com/fastai/fastai/blob/master/fastai/core.py\n",
    "# https://github.com/fastai/course-nlp/blob/master/nlputils.py\n",
    "\n",
    "# wikiextractor : Guiseppe Attardi\n",
    "# https://github.com/attardi/wikiextractor\n",
    "\n",
    "# NLP & fastai | French Language Model : Pierre Guillou\n",
    "# https://medium.com/@pierre_guillou/nlp-fastai-french-language-model-d0e2a9e12cab\n",
    "# https://github.com/piegu/language-models/blob/master/nlputils2.py\n",
    "\n",
    "import bz2\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "from pathlib import Path\n",
    "Path.ls = lambda x: list(x.iterdir())\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "def get_wiki_download(path,lang):\n",
    "    name = f'{lang}wiki'\n",
    "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
    "    zip_fn = f\"{xml_fn}.bz2\"    \n",
    "    \n",
    "    if (path/zip_fn).exists():\n",
    "        print(f\"{path/zip_fn} already exists; not downloading\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"downloading...\")\n",
    "        download_url(f'https://dumps.wikimedia.org/{name}/latest/{zip_fn}', path/zip_fn)\n",
    "\n",
    "def get_wiki_unzip(path,lang):\n",
    "    name = f'{lang}wiki'\n",
    "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
    "    zip_fn = f\"{xml_fn}.bz2\"\n",
    "    \n",
    "    if (path/xml_fn).exists():\n",
    "        print(f\"{path/xml_fn} already exists; not unzip\")\n",
    "        return    \n",
    "    else:\n",
    "        print(\"unzipping...\")\n",
    "        bunzip(path/zip_fn)\n",
    "    \n",
    "def get_wiki_extract(path,lang):\n",
    "    name = f'{lang}wiki'\n",
    "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
    "    zip_fn = f\"{xml_fn}.bz2\"\n",
    "\n",
    "    with working_directory(path):\n",
    "        \n",
    "        # get updated wikiextractor folder from albertvillanova, not attardi\n",
    "        if not (path/'wikiextractor').exists(): os.system('git clone https://github.com/attardi/wikiextractor.git')\n",
    "#         if not (path/'wikiextractor').exists(): os.system('git clone https://github.com/albertvillanova/wikiextractor.git')\n",
    "        \n",
    "        # if you cloned the wikiextractor folder from attardi, get the platform-independent WikiExtractor.py file with this code\n",
    "        file_path = path/'wikiextractor/WikiExtractor.py'\n",
    "        os.unlink(file_path) # delete existing file\n",
    "        url = 'https://raw.githubusercontent.com/piegu/fastai-projects/master/WikiExtractor.py' # updated file url\n",
    "        urllib.request.urlretrieve(url, file_path) # get updated file\n",
    "        \n",
    "        if (path/'wikiextractor/WikiExtractor.py').exists(): \n",
    "            print(\"extracting...\")\n",
    "            os.system(\"python wikiextractor/WikiExtractor.py --processes 4 --no_templates \" +\n",
    "                f\"--min_text_length 1800 --filter_disambig_pages --log_file log -b 100G -q {xml_fn}\")\n",
    "            shutil.move(str(path/'text/AA/wiki_00'), str(path/name))\n",
    "            shutil.rmtree(path/'text')\n",
    "        else:\n",
    "            print(f\"the file {path}\\wikiextractor\\WikiExtractor.py does not exist\")\n",
    "\n",
    "def split_wiki2(path,lang):\n",
    "    dest = path/'docs'\n",
    "    name = f'{lang}wiki'\n",
    "    if dest.exists():\n",
    "        print(f\"{dest} already exists; not splitting\")\n",
    "        return dest\n",
    "\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    title_re = re.compile(rf'<doc id=\"\\d+\" url=\"https://{lang}.wikipedia.org/wiki\\?curid=\\d+\" title=\"([^\"]+)\">')\n",
    "#     re_punc = re.compile(\"([\\\"'().,;:/_?!â€”\\-*])\") # replace ponctuation\n",
    "    re_punc = re.compile(\"([^a-zA-Z0-9])\") # replace ponctuation in title\n",
    "\n",
    "#     lines = (path/name).open()\n",
    "    lines = (path/name).open(encoding=\"utf8\") # platform independent with utf8\n",
    "    \n",
    "    f=None\n",
    "\n",
    "    for i,l in enumerate(lines):\n",
    "        if i%100000 == 0: print(f\"{i} lines\", end='\\r', flush=True)\n",
    "        if l.startswith('<doc id=\"'):\n",
    "#             title = title_re.findall(l)[0].replace('/','_')\n",
    "            title = title_re.findall(l)[0]\n",
    "            title = re_punc.sub(r\"_\", title)\n",
    "            if len(title)>150: continue\n",
    "            if title == \"Com8\": continue # exception\n",
    "            if f: f.close()\n",
    "#             f = (dest/f'{title}.txt').open('w')\n",
    "            f = (dest/f'{title}.txt').open('w', encoding=\"utf8\") # platform independent with utf8\n",
    "        else: f.write(l)\n",
    "    f.close()\n",
    "    return dest\n",
    "\n",
    "\n",
    "def clean_files(path,folder):\n",
    "\n",
    "    dest = path/folder\n",
    "    doc_re = re.compile(rf'([\\w\\W]*)<\\/doc>') # delete </doc>\n",
    "               \n",
    "    for i,l in enumerate(dest.ls()):\n",
    "        # open file and get content without first line which is the title\n",
    "        f = l.open('r+', encoding=\"utf-8\")\n",
    "        f.readline()\n",
    "        text = f.read()\n",
    "        # get content without </doc> and delete empty line and whitespaces at the head and tail\n",
    "        text = doc_re.findall(text)[0].strip()\n",
    "        # delete file content\n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        # write modificated text in file\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "\n",
    "def get_num_tokens(dest):\n",
    "    \n",
    "    # Getting an idea of the number of words\n",
    "    files = dest.ls()\n",
    "    num_tokens = 0\n",
    "\n",
    "    for i,l in enumerate(files):\n",
    "        f = l.open('r', encoding=\"utf-8\")\n",
    "        words = f.read()\n",
    "        num_tokens += len(words.split())\n",
    "        f.close()\n",
    "        \n",
    "    num_files = i+1\n",
    "    \n",
    "    return num_files, num_tokens\n",
    "\n",
    "# Create a corpus of about obj_token words in a corpus_'obj_token' folder\n",
    "def get_corpus(dest, path, num_tokens, obj_tokens=int(1e8)):\n",
    "    \n",
    "    num_tokens_article_min = 100\n",
    "    \n",
    "    if num_tokens >= obj_tokens:\n",
    "    \n",
    "        # number of tokens by text\n",
    "        files = dest.ls()\n",
    "        sizes = []\n",
    "        list_idx = []\n",
    "\n",
    "        for i,f in enumerate(files):\n",
    "            sizes.append(os.path.getsize(f))\n",
    "\n",
    "        total_size = np.array(sizes).astype(np.int64).sum()\n",
    "        tokens_by_file = np.array(sizes)*(num_tokens/total_size)\n",
    "\n",
    "        # Sorted list of texts ids \n",
    "        num = 0\n",
    "\n",
    "        tokens_by_file_sorted = np.argsort(tokens_by_file)\n",
    "\n",
    "        #for i,idx in enumerate(tokens_by_file_sorted[:-len(tokens_by_file_sorted)-1:-1]):\n",
    "        for i,idx in enumerate(tokens_by_file_sorted):\n",
    "            if tokens_by_file[idx] >= num_tokens_article_min:\n",
    "                num += tokens_by_file[idx]\n",
    "                list_idx.append(i)\n",
    "            if num >= obj_tokens: break\n",
    "\n",
    "        articles_idxs = tokens_by_file_sorted[list_idx]\n",
    "\n",
    "        # creation of the corpus folder\n",
    "        folder = 'corpus_'+str(int(obj_tokens))\n",
    "        path_corpus = path/folder\n",
    "        path_corpus.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # copy text files to corpus folder\n",
    "        for idx in articles_idxs:\n",
    "            file = files[idx]\n",
    "            shutil.copy(str(file), str(path_corpus))\n",
    "\n",
    "        print(f'files copied to the new corpus folder: {path/folder}')\n",
    "\n",
    "        return path_corpus\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('As there are less than 100 000 000 tokens in the initial corpus, we use it.')\n",
    "        \n",
    "        return dest\n",
    "    \n",
    "def download_url(url:str, dest:str, overwrite:bool=False, show_progress=True, \n",
    "                 chunk_size=1024*1024, timeout=4, retries=5)->None:\n",
    "    \"Download `url` to `dest` unless it exists and not `overwrite`.\"\n",
    "    if os.path.exists(dest) and not overwrite: return\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.mount('http://',requests.adapters.HTTPAdapter(max_retries=retries))\n",
    "    # additional line to identify as a firefox browser, see #2438\n",
    "    s.headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0'}) \n",
    "    u = s.get(url, stream=True, timeout=timeout)\n",
    "    try: file_size = int(u.headers[\"Content-Length\"])\n",
    "    except: show_progress = False\n",
    "\n",
    "    with open(dest, 'wb') as f:\n",
    "        cntMB = 0\n",
    "        try:           \n",
    "            for chunk in u.iter_content(chunk_size=chunk_size):\n",
    "                cntMB += 1\n",
    "                if show_progress: print(f\"{cntMB} MB\", end='\\r', flush=True)\n",
    "                f.write(chunk)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            fname = url.split('/')[-1]\n",
    "            print(f'\\n Download of {url} has failed after {retries} retries')\n",
    "            import sys;sys.exit(1)\n",
    "            \n",
    "def bunzip(fn):\n",
    "    \"bunzip `fn`, raising exception if output already exists\"\n",
    "    fn = Path(fn)\n",
    "    assert fn.exists(), f\"{fn} doesn't exist\"\n",
    "    out_fn = fn.with_suffix('')\n",
    "    assert not out_fn.exists(), f\"{out_fn} already exists\"\n",
    "    with bz2.BZ2File(fn, 'rb') as src, out_fn.open('wb') as dst:\n",
    "        for d in iter(lambda: src.read(1024*1024), b''): dst.write(d)\n",
    "        \n",
    "@contextmanager\n",
    "def working_directory(path):\n",
    "    \"Change working directory to `path` and return to previous on exit.\"\n",
    "    prev_cwd = Path.cwd()\n",
    "    os.chdir(path)\n",
    "    try: yield\n",
    "    finally: os.chdir(prev_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the root path to download the Wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "rootdir = Path(r\"\\\\?\\C:\\tmp\\wikipedia\")\n",
    "\n",
    "lang = 'fr'\n",
    "name = f'{lang}wiki'\n",
    "path = rootdir/name\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download \"frwiki-latest-pages-articles.xml.bz2\" (4.5 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_wiki_download(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decompress the archive to \"frwiki-latest-pages-articles.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_wiki_unzip(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract plain text from the Wikipedia dump in \"frwiki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_wiki_extract(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split plain text Wikipedia contents in individual text files in the \"./doc\" directory (one file per article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dest = split_wiki2(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Clean the extracted text files (in place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"docs\"\n",
    "%time clean_files(path,folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package wikipedia text files in one nlptextdoc DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class WikipediaDocsReader:\n",
    "    \"\"\"Read output files of a wikipedia extraction in one pandas DataFrame.\n",
    "    \"\"\"    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.docsdir = path / \"docs\"\n",
    "        \n",
    "        self.documentCount = 0 \n",
    "        self.nestingLevel = 1\n",
    "        self.listDocId = []\n",
    "        self.listType = []\n",
    "        self.listCmd = []\n",
    "        self.listLevel = []\n",
    "        self.listText = []\n",
    "        \n",
    "    def load_dataframe(self):\n",
    "        textdffile = self.docsdir / \"nlptextdocs.dataframe.feather\"\n",
    "        if(textdffile.exists()):\n",
    "            return pd.read_feather(textdffile)\n",
    "        else:\n",
    "            i = 0\n",
    "            for textfile in self.docsdir.glob(\"*.txt\"):                \n",
    "                with textfile.open(mode=\"r\", encoding=\"utf-8-sig\") as f:   \n",
    "                    self.textfile = textfile\n",
    "                    self.documentCount = self.documentCount+1\n",
    "                    self.onDocumentStart(str(self.documentCount))\n",
    "                    self.onDocumentUri(textfile.name)\n",
    "                    self.onDocumentTitle(textfile.stem.replace(\"_\",\" \"))\n",
    "                    for lineidx,line in enumerate(f):\n",
    "                        line = line.strip()\n",
    "                        if(not line): continue\n",
    "                        self.lineidx = lineidx\n",
    "                        self.readline(line)\n",
    "                    self.onDocumentEnd(str(self.documentCount))\n",
    "                i = i + 1\n",
    "                if(i%1000 == 0):\n",
    "                    print(f\"{i} articles\", end='\\r', flush=True)\n",
    "                if(i%100000 == 0):\n",
    "                    self.write_dataframe(str(i)+\".\")\n",
    "            textdf = self.write_dataframe(str(i)+\".\")            \n",
    "            return textdf\n",
    "\n",
    "    def write_dataframe(self,prefix=\"\"):\n",
    "        textdf = pd.DataFrame({\"DocId\": self.listDocId, \"DocEltType\": self.listType, \"DocEltCmd\" : self.listCmd, \"NestingLevel\": self.listLevel, \"Text\":self.listText})\n",
    "        textdf = textdf.astype({\"DocEltType\": \"category\", \"DocEltCmd\": \"category\", \"NestingLevel\": np.uint8},copy=False)\n",
    "        textdffile = self.path / (prefix + \"nlptextdocs.dataframe.feather\")\n",
    "        textdf.to_feather(textdffile)\n",
    "        self.__init__(self.path)\n",
    "        return textdf\n",
    "        \n",
    "    def readline(self,line):\n",
    "        self.onTextBlock(line)\n",
    "        \n",
    "    def onDocumentStart(self,docId):\n",
    "        self.appendrow(\"Document\",\"Start\",docId)\n",
    "    \n",
    "    def onDocumentTitle(self,title):\n",
    "        self.appendrow(\"Document\",\"Title\",title)\n",
    "            \n",
    "    def onDocumentUri(self,uri):\n",
    "        self.appendrow(\"Document\",\"Uri\",uri)\n",
    "    \n",
    "    def onDocumentEnd(self,docId):\n",
    "        self.appendrow(\"Document\",\"End\",docId)\n",
    "    \n",
    "    def onTextBlock(self,text):\n",
    "        self.appendrow(\"TextBlock\",\"Text\",text)  \n",
    "            \n",
    "    def appendrow(self,docEltType,docEltCmd,text=None):\n",
    "        self.listDocId.append(self.documentCount)\n",
    "        self.listType.append(docEltType)\n",
    "        self.listCmd.append(docEltCmd)\n",
    "        self.listLevel.append(self.nestingLevel)\n",
    "        if(text != None):\n",
    "            text = text.replace(\"\\\\n\",\"\\n\")\n",
    "        self.listText.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000 articles\r"
     ]
    }
   ],
   "source": [
    "wikireader = WikipediaDocsReader(path)\n",
    "textdf = wikireader.load_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocId</th>\n",
       "      <th>DocEltType</th>\n",
       "      <th>DocEltCmd</th>\n",
       "      <th>NestingLevel</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>Start</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>Uri</td>\n",
       "      <td>1</td>\n",
       "      <td>1000_bornes.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>1000 bornes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Les 1000 bornes est un jeu de sociÃ©tÃ© utilisan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Sur les premiÃ¨res boÃ®tes du jeu, il Ã©tait sous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Depuis 2009, la fabrication se fait Ã  l'usine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le jeu comprend 106 cartes. Les deux joueurs d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>La libertÃ© du joueur est surtout dans la dÃ©cis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Les images de cartes suivantes sont celles de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Les distances parcourues sont associÃ©es Ã  des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le jeu comporte 106 cartes :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Depuis 1954, outre les rÃ©Ã©ditions du jeu stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>End</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>Start</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>Uri</td>\n",
       "      <td>1</td>\n",
       "      <td>1000_De_La_Gaucheti_re.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>1000 De La Gaucheti re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le 1000 De La GauchetiÃ¨re est le plus haut gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>La tour a Ã©tÃ© dessinÃ© par Lemay &amp; AssociÃ©s et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le 1000 de la GauchetiÃ¨re a Ã©tÃ© construit par ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Au moment de sa construction, le 1000 de la Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Ce lieu est reliÃ© au MontrÃ©al souterrain (le R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Sa forme caractÃ©ristique en flÃ¨che domine et d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Exemple d'architecture post-moderne fortement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le premier Ã©tage comporte une patinoire intÃ©ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>End</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>Document</td>\n",
       "      <td>Start</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Document</td>\n",
       "      <td>Uri</td>\n",
       "      <td>1</td>\n",
       "      <td>100e_r_giment_d_infanterie.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>Document</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>100e r giment d infanterie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le d'infanterie ( RI) est un rÃ©giment d'infant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Colonels tuÃ©s et blessÃ©s Ã  la tÃªte du :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Officiers tuÃ©s et blessÃ©s durant leur service ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1849 : prise de Rome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le dÃ©cret du 24 octobre 1854 rÃ©organise les rÃ©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1881-1888 : le rÃ©giment est AlgÃ©rie&lt;br&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1881 : le fait la campagne de Tunisie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1907 : en garnison Ã  Narbonne durant la rÃ©volt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Affectation : casernement Tulle, DI, DI, d'armÃ©e.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Bataille de Vitry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Verdun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Seconde bataille de la Marne en 1918.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>FormÃ© le par le CMI 12 (Centre Mobilisateur d'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>RÃ©giment de rÃ©serve, dÃ©rivÃ© du RÃ©giment d'Infa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>le rÃ©giment est dissous en 1998.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Il porte, cousues en lettres d'or dans ses pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Sa cravate est dÃ©corÃ©e de la Croix de guerre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Il a le droit au port de la fourragÃ¨re aux co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Survivance, cette cravate portait aussi la mÃ©d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"N'a peur de rien et comme Cambronne il le dit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Pro Rege et Patria!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Nous sommes tous grenadiers!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DocId DocEltType DocEltCmd  NestingLevel  \\\n",
       "0       1   Document     Start             1   \n",
       "1       1   Document       Uri             1   \n",
       "2       1   Document     Title             1   \n",
       "3       1  TextBlock      Text             1   \n",
       "4       1  TextBlock      Text             1   \n",
       "5       1  TextBlock      Text             1   \n",
       "6       1  TextBlock      Text             1   \n",
       "7       1  TextBlock      Text             1   \n",
       "8       1  TextBlock      Text             1   \n",
       "9       1  TextBlock      Text             1   \n",
       "10      1  TextBlock      Text             1   \n",
       "11      1  TextBlock      Text             1   \n",
       "12      1   Document       End             1   \n",
       "13      2   Document     Start             1   \n",
       "14      2   Document       Uri             1   \n",
       "15      2   Document     Title             1   \n",
       "16      2  TextBlock      Text             1   \n",
       "17      2  TextBlock      Text             1   \n",
       "18      2  TextBlock      Text             1   \n",
       "19      2  TextBlock      Text             1   \n",
       "20      2  TextBlock      Text             1   \n",
       "21      2  TextBlock      Text             1   \n",
       "22      2  TextBlock      Text             1   \n",
       "23      2  TextBlock      Text             1   \n",
       "24      2   Document       End             1   \n",
       "25      3   Document     Start             1   \n",
       "26      3   Document       Uri             1   \n",
       "27      3   Document     Title             1   \n",
       "28      3  TextBlock      Text             1   \n",
       "29      3  TextBlock      Text             1   \n",
       "30      3  TextBlock      Text             1   \n",
       "31      3  TextBlock      Text             1   \n",
       "32      3  TextBlock      Text             1   \n",
       "33      3  TextBlock      Text             1   \n",
       "34      3  TextBlock      Text             1   \n",
       "35      3  TextBlock      Text             1   \n",
       "36      3  TextBlock      Text             1   \n",
       "37      3  TextBlock      Text             1   \n",
       "38      3  TextBlock      Text             1   \n",
       "39      3  TextBlock      Text             1   \n",
       "40      3  TextBlock      Text             1   \n",
       "41      3  TextBlock      Text             1   \n",
       "42      3  TextBlock      Text             1   \n",
       "43      3  TextBlock      Text             1   \n",
       "44      3  TextBlock      Text             1   \n",
       "45      3  TextBlock      Text             1   \n",
       "46      3  TextBlock      Text             1   \n",
       "47      3  TextBlock      Text             1   \n",
       "48      3  TextBlock      Text             1   \n",
       "49      3  TextBlock      Text             1   \n",
       "\n",
       "                                                 Text  \n",
       "0                                                   1  \n",
       "1                                     1000_bornes.txt  \n",
       "2                                         1000 bornes  \n",
       "3   Les 1000 bornes est un jeu de sociÃ©tÃ© utilisan...  \n",
       "4   Sur les premiÃ¨res boÃ®tes du jeu, il Ã©tait sous...  \n",
       "5   Depuis 2009, la fabrication se fait Ã  l'usine ...  \n",
       "6   Le jeu comprend 106 cartes. Les deux joueurs d...  \n",
       "7   La libertÃ© du joueur est surtout dans la dÃ©cis...  \n",
       "8   Les images de cartes suivantes sont celles de ...  \n",
       "9   Les distances parcourues sont associÃ©es Ã  des ...  \n",
       "10                       Le jeu comporte 106 cartes :  \n",
       "11  Depuis 1954, outre les rÃ©Ã©ditions du jeu stand...  \n",
       "12                                                  1  \n",
       "13                                                  2  \n",
       "14                         1000_De_La_Gaucheti_re.txt  \n",
       "15                             1000 De La Gaucheti re  \n",
       "16  Le 1000 De La GauchetiÃ¨re est le plus haut gra...  \n",
       "17  La tour a Ã©tÃ© dessinÃ© par Lemay & AssociÃ©s et ...  \n",
       "18  Le 1000 de la GauchetiÃ¨re a Ã©tÃ© construit par ...  \n",
       "19  Au moment de sa construction, le 1000 de la Ga...  \n",
       "20  Ce lieu est reliÃ© au MontrÃ©al souterrain (le R...  \n",
       "21  Sa forme caractÃ©ristique en flÃ¨che domine et d...  \n",
       "22  Exemple d'architecture post-moderne fortement ...  \n",
       "23  Le premier Ã©tage comporte une patinoire intÃ©ri...  \n",
       "24                                                  2  \n",
       "25                                                  3  \n",
       "26                     100e_r_giment_d_infanterie.txt  \n",
       "27                         100e r giment d infanterie  \n",
       "28  Le d'infanterie ( RI) est un rÃ©giment d'infant...  \n",
       "29            Colonels tuÃ©s et blessÃ©s Ã  la tÃªte du :  \n",
       "30  Officiers tuÃ©s et blessÃ©s durant leur service ...  \n",
       "31                               1849 : prise de Rome  \n",
       "32  Le dÃ©cret du 24 octobre 1854 rÃ©organise les rÃ©...  \n",
       "33            1881-1888 : le rÃ©giment est AlgÃ©rie<br>  \n",
       "34              1881 : le fait la campagne de Tunisie  \n",
       "35  1907 : en garnison Ã  Narbonne durant la rÃ©volt...  \n",
       "36  Affectation : casernement Tulle, DI, DI, d'armÃ©e.  \n",
       "37                                  Bataille de Vitry  \n",
       "38                                             Verdun  \n",
       "39              Seconde bataille de la Marne en 1918.  \n",
       "40  FormÃ© le par le CMI 12 (Centre Mobilisateur d'...  \n",
       "41  RÃ©giment de rÃ©serve, dÃ©rivÃ© du RÃ©giment d'Infa...  \n",
       "42                   le rÃ©giment est dissous en 1998.  \n",
       "43  \"Il porte, cousues en lettres d'or dans ses pl...  \n",
       "44  \"Sa cravate est dÃ©corÃ©e de la Croix de guerre ...  \n",
       "45  \"Il a le droit au port de la fourragÃ¨re aux co...  \n",
       "46  Survivance, cette cravate portait aussi la mÃ©d...  \n",
       "47  \"N'a peur de rien et comme Cambronne il le dit...  \n",
       "48                                Pro Rege et Patria!  \n",
       "49                       Nous sommes tous grenadiers!  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "rootdir = Path(r\"\\\\?\\D:\\Laurent\\nlptextdoc-data-201909\")\n",
    "\n",
    "websites = []\n",
    "\n",
    "SCOPE_KEY = \"scope=\"\n",
    "URL_KEY=\"rootUrl=\"\n",
    "\n",
    "for entry in os.scandir(rootdir):\n",
    "    if entry.is_dir():\n",
    "        websitedir = Path(entry)\n",
    "        if(not websitedir.name.startswith(\"wikipedia-\")):\n",
    "            continue\n",
    "        configfile = websitedir / \"_nlptextdoc\" / \"config.txt\"\n",
    "        scope = \"\"\n",
    "        if configfile.exists():\n",
    "            with configfile.open(mode=\"r\", encoding=\"utf-8-sig\") as f:   \n",
    "                for lineidx,line in enumerate(f):\n",
    "                    line = line.strip()\n",
    "                    if (line.startswith(SCOPE_KEY)):\n",
    "                        scope = line[len(SCOPE_KEY):]\n",
    "                    if (line.startswith(URL_KEY)):\n",
    "                        url = line[len(URL_KEY):]\n",
    "                        websites.append((scope,url,websitedir))\n",
    "                        break\n",
    "                \n",
    "websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "websitedir = websites[0][2]\n",
    "textdffile = websitedir / \"_nlptextdoc\" / \"nlptextdocs.dataframe.feather\"\n",
    "textdf = pd.read_feather(textdffile)\n",
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_urls_dataframe(websitedir):\n",
    "    urlsdffile = websitedir / \"_nlptextdoc\" / \"urls.dataframe.feather\" \n",
    "    if(urlsdffile.exists()):\n",
    "            return pd.read_feather(urlsdffile)\n",
    "    else:\n",
    "        listDocUrls = []\n",
    "        textdffile = websitedir / \"_nlptextdoc\" / \"nlptextdocs.dataframe.feather\"\n",
    "        textdf = pd.read_feather(textdffile)\n",
    "        for rowidx,row in textdf[textdf[\"DocEltCmd\"] == \"Uri\"].iterrows():\n",
    "            article = Path(row[\"Text\"]).stem\n",
    "            listDocUrls.append(\"https://fr.wikipedia.org/wiki/\"+article)\n",
    "        urlsdf = pd.DataFrame({\"DocId\" : range(1,len(listDocUrls)+1), \"DocUrl\" : listDocUrls})\n",
    "        urlsdf = urlsdf.astype({\"DocId\" : np.uint32},copy=False)\n",
    "        urlsdf.to_feather(urlsdffile)     \n",
    "        return urlsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsdf = gen_urls_dataframe(websites[5][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
