{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download wikipedia and extract one text file per article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastai : Jeremy Howard / Sylvain Gugger\n",
    "# https://github.com/fastai/fastai/blob/master/fastai/core.py\n",
    "# https://github.com/fastai/course-nlp/blob/master/nlputils.py\n",
    "\n",
    "# wikiextractor : Guiseppe Attardi\n",
    "# https://github.com/attardi/wikiextractor\n",
    "\n",
    "# NLP & fastai | French Language Model : Pierre Guillou\n",
    "# https://medium.com/@pierre_guillou/nlp-fastai-french-language-model-d0e2a9e12cab\n",
    "# https://github.com/piegu/language-models/blob/master/nlputils2.py\n",
    "\n",
    "import bz2\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "from pathlib import Path\n",
    "Path.ls = lambda x: list(x.iterdir())\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "def get_wiki_download(path,lang):\n",
    "    name = f'{lang}wiki'\n",
    "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
    "    zip_fn = f\"{xml_fn}.bz2\"    \n",
    "    \n",
    "    if (path/zip_fn).exists():\n",
    "        print(f\"{path/zip_fn} already exists; not downloading\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"downloading...\")\n",
    "        download_url(f'https://dumps.wikimedia.org/{name}/latest/{zip_fn}', path/zip_fn)\n",
    "\n",
    "def get_wiki_unzip(path,lang):\n",
    "    name = f'{lang}wiki'\n",
    "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
    "    zip_fn = f\"{xml_fn}.bz2\"\n",
    "    \n",
    "    if (path/xml_fn).exists():\n",
    "        print(f\"{path/xml_fn} already exists; not unzip\")\n",
    "        return    \n",
    "    else:\n",
    "        print(\"unzipping...\")\n",
    "        bunzip(path/zip_fn)\n",
    "    \n",
    "def get_wiki_extract(path,lang):\n",
    "    name = f'{lang}wiki'\n",
    "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
    "    zip_fn = f\"{xml_fn}.bz2\"\n",
    "\n",
    "    with working_directory(path):\n",
    "        \n",
    "        # get updated wikiextractor folder from albertvillanova, not attardi\n",
    "        if not (path/'wikiextractor').exists(): os.system('git clone https://github.com/attardi/wikiextractor.git')\n",
    "#         if not (path/'wikiextractor').exists(): os.system('git clone https://github.com/albertvillanova/wikiextractor.git')\n",
    "        \n",
    "        # if you cloned the wikiextractor folder from attardi, get the platform-independent WikiExtractor.py file with this code\n",
    "        file_path = path/'wikiextractor/WikiExtractor.py'\n",
    "        os.unlink(file_path) # delete existing file\n",
    "        url = 'https://raw.githubusercontent.com/piegu/fastai-projects/master/WikiExtractor.py' # updated file url\n",
    "        urllib.request.urlretrieve(url, file_path) # get updated file\n",
    "        \n",
    "        if (path/'wikiextractor/WikiExtractor.py').exists(): \n",
    "            print(\"extracting...\")\n",
    "            os.system(\"python wikiextractor/WikiExtractor.py --processes 4 --no_templates \" +\n",
    "                f\"--min_text_length 1800 --filter_disambig_pages --log_file log -b 100G -q {xml_fn}\")\n",
    "            shutil.move(str(path/'text/AA/wiki_00'), str(path/name))\n",
    "            shutil.rmtree(path/'text')\n",
    "        else:\n",
    "            print(f\"the file {path}\\wikiextractor\\WikiExtractor.py does not exist\")\n",
    "\n",
    "def split_wiki2(path,lang):\n",
    "    dest = path/'docs'\n",
    "    name = f'{lang}wiki'\n",
    "    if dest.exists():\n",
    "        print(f\"{dest} already exists; not splitting\")\n",
    "        return dest\n",
    "\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    title_re = re.compile(rf'<doc id=\"\\d+\" url=\"https://{lang}.wikipedia.org/wiki\\?curid=\\d+\" title=\"([^\"]+)\">')\n",
    "#     re_punc = re.compile(\"([\\\"'().,;:/_?!—\\-*])\") # replace ponctuation\n",
    "    re_punc = re.compile(\"([^a-zA-Z0-9])\") # replace ponctuation in title\n",
    "\n",
    "#     lines = (path/name).open()\n",
    "    lines = (path/name).open(encoding=\"utf8\") # platform independent with utf8\n",
    "    \n",
    "    f=None\n",
    "\n",
    "    for i,l in enumerate(lines):\n",
    "        if i%100000 == 0: print(f\"{i} lines\", end='\\r', flush=True)\n",
    "        if l.startswith('<doc id=\"'):\n",
    "#             title = title_re.findall(l)[0].replace('/','_')\n",
    "            title = title_re.findall(l)[0]\n",
    "            title = re_punc.sub(r\"_\", title)\n",
    "            if len(title)>150: continue\n",
    "            if title == \"Com8\": continue # exception\n",
    "            if f: f.close()\n",
    "#             f = (dest/f'{title}.txt').open('w')\n",
    "            f = (dest/f'{title}.txt').open('w', encoding=\"utf8\") # platform independent with utf8\n",
    "        else: f.write(l)\n",
    "    f.close()\n",
    "    return dest\n",
    "\n",
    "\n",
    "def clean_files(path,folder):\n",
    "\n",
    "    dest = path/folder\n",
    "    doc_re = re.compile(rf'([\\w\\W]*)<\\/doc>') # delete </doc>\n",
    "               \n",
    "    for i,l in enumerate(dest.ls()):\n",
    "        # open file and get content without first line which is the title\n",
    "        f = l.open('r+', encoding=\"utf-8\")\n",
    "        f.readline()\n",
    "        text = f.read()\n",
    "        # get content without </doc> and delete empty line and whitespaces at the head and tail\n",
    "        text = doc_re.findall(text)[0].strip()\n",
    "        # delete file content\n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        # write modificated text in file\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "\n",
    "def get_num_tokens(dest):\n",
    "    \n",
    "    # Getting an idea of the number of words\n",
    "    files = dest.ls()\n",
    "    num_tokens = 0\n",
    "\n",
    "    for i,l in enumerate(files):\n",
    "        f = l.open('r', encoding=\"utf-8\")\n",
    "        words = f.read()\n",
    "        num_tokens += len(words.split())\n",
    "        f.close()\n",
    "        \n",
    "    num_files = i+1\n",
    "    \n",
    "    return num_files, num_tokens\n",
    "\n",
    "# Create a corpus of about obj_token words in a corpus_'obj_token' folder\n",
    "def get_corpus(dest, path, num_tokens, obj_tokens=int(1e8)):\n",
    "    \n",
    "    num_tokens_article_min = 100\n",
    "    \n",
    "    if num_tokens >= obj_tokens:\n",
    "    \n",
    "        # number of tokens by text\n",
    "        files = dest.ls()\n",
    "        sizes = []\n",
    "        list_idx = []\n",
    "\n",
    "        for i,f in enumerate(files):\n",
    "            sizes.append(os.path.getsize(f))\n",
    "\n",
    "        total_size = np.array(sizes).astype(np.int64).sum()\n",
    "        tokens_by_file = np.array(sizes)*(num_tokens/total_size)\n",
    "\n",
    "        # Sorted list of texts ids \n",
    "        num = 0\n",
    "\n",
    "        tokens_by_file_sorted = np.argsort(tokens_by_file)\n",
    "\n",
    "        #for i,idx in enumerate(tokens_by_file_sorted[:-len(tokens_by_file_sorted)-1:-1]):\n",
    "        for i,idx in enumerate(tokens_by_file_sorted):\n",
    "            if tokens_by_file[idx] >= num_tokens_article_min:\n",
    "                num += tokens_by_file[idx]\n",
    "                list_idx.append(i)\n",
    "            if num >= obj_tokens: break\n",
    "\n",
    "        articles_idxs = tokens_by_file_sorted[list_idx]\n",
    "\n",
    "        # creation of the corpus folder\n",
    "        folder = 'corpus_'+str(int(obj_tokens))\n",
    "        path_corpus = path/folder\n",
    "        path_corpus.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # copy text files to corpus folder\n",
    "        for idx in articles_idxs:\n",
    "            file = files[idx]\n",
    "            shutil.copy(str(file), str(path_corpus))\n",
    "\n",
    "        print(f'files copied to the new corpus folder: {path/folder}')\n",
    "\n",
    "        return path_corpus\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('As there are less than 100 000 000 tokens in the initial corpus, we use it.')\n",
    "        \n",
    "        return dest\n",
    "    \n",
    "def download_url(url:str, dest:str, overwrite:bool=False, show_progress=True, \n",
    "                 chunk_size=1024*1024, timeout=4, retries=5)->None:\n",
    "    \"Download `url` to `dest` unless it exists and not `overwrite`.\"\n",
    "    if os.path.exists(dest) and not overwrite: return\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.mount('http://',requests.adapters.HTTPAdapter(max_retries=retries))\n",
    "    # additional line to identify as a firefox browser, see #2438\n",
    "    s.headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0'}) \n",
    "    u = s.get(url, stream=True, timeout=timeout)\n",
    "    try: file_size = int(u.headers[\"Content-Length\"])\n",
    "    except: show_progress = False\n",
    "\n",
    "    with open(dest, 'wb') as f:\n",
    "        cntMB = 0\n",
    "        try:           \n",
    "            for chunk in u.iter_content(chunk_size=chunk_size):\n",
    "                cntMB += 1\n",
    "                if show_progress: print(f\"{cntMB} MB\", end='\\r', flush=True)\n",
    "                f.write(chunk)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            fname = url.split('/')[-1]\n",
    "            print(f'\\n Download of {url} has failed after {retries} retries')\n",
    "            import sys;sys.exit(1)\n",
    "            \n",
    "def bunzip(fn):\n",
    "    \"bunzip `fn`, raising exception if output already exists\"\n",
    "    fn = Path(fn)\n",
    "    assert fn.exists(), f\"{fn} doesn't exist\"\n",
    "    out_fn = fn.with_suffix('')\n",
    "    assert not out_fn.exists(), f\"{out_fn} already exists\"\n",
    "    with bz2.BZ2File(fn, 'rb') as src, out_fn.open('wb') as dst:\n",
    "        for d in iter(lambda: src.read(1024*1024), b''): dst.write(d)\n",
    "        \n",
    "@contextmanager\n",
    "def working_directory(path):\n",
    "    \"Change working directory to `path` and return to previous on exit.\"\n",
    "    prev_cwd = Path.cwd()\n",
    "    os.chdir(path)\n",
    "    try: yield\n",
    "    finally: os.chdir(prev_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the root path to download the Wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "rootdir = Path(r\"\\\\?\\C:\\tmp\\wikipedia\")\n",
    "\n",
    "lang = 'fr'\n",
    "name = f'{lang}wiki'\n",
    "path = rootdir/name\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download \"frwiki-latest-pages-articles.xml.bz2\" (4.5 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_wiki_download(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decompress the archive to \"frwiki-latest-pages-articles.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_wiki_unzip(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract plain text from the Wikipedia dump in \"frwiki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time get_wiki_extract(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split plain text Wikipedia contents in individual text files in the \"./doc\" directory (one file per article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dest = split_wiki2(path,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Clean the extracted text files (in place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"docs\"\n",
    "%time clean_files(path,folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package wikipedia text files in one nlptextdoc DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class WikipediaDocsReader:\n",
    "    \"\"\"Read output files of a wikipedia extraction in one pandas DataFrame.\n",
    "    \"\"\"    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.docsdir = path / \"docs\"\n",
    "        \n",
    "        self.documentCount = 0 \n",
    "        self.nestingLevel = 1\n",
    "        self.listDocId = []\n",
    "        self.listType = []\n",
    "        self.listCmd = []\n",
    "        self.listLevel = []\n",
    "        self.listText = []\n",
    "        \n",
    "    def load_dataframe(self):\n",
    "        textdffile = self.docsdir / \"nlptextdocs.dataframe.feather\"\n",
    "        if(textdffile.exists()):\n",
    "            return pd.read_feather(textdffile)\n",
    "        else:\n",
    "            i = 0\n",
    "            for textfile in self.docsdir.glob(\"*.txt\"):                \n",
    "                with textfile.open(mode=\"r\", encoding=\"utf-8-sig\") as f:   \n",
    "                    self.textfile = textfile\n",
    "                    self.documentCount = self.documentCount+1\n",
    "                    self.onDocumentStart(str(self.documentCount))\n",
    "                    self.onDocumentUri(textfile.name)\n",
    "                    self.onDocumentTitle(textfile.stem.replace(\"_\",\" \"))\n",
    "                    for lineidx,line in enumerate(f):\n",
    "                        line = line.strip()\n",
    "                        if(not line): continue\n",
    "                        self.lineidx = lineidx\n",
    "                        self.readline(line)\n",
    "                    self.onDocumentEnd(str(self.documentCount))\n",
    "                i = i + 1\n",
    "                if(i%1000 == 0):\n",
    "                    print(f\"{i} articles\", end='\\r', flush=True)\n",
    "                if(i%100000 == 0):\n",
    "                    self.write_dataframe(str(i)+\".\")\n",
    "            textdf = self.write_dataframe(str(i)+\".\")            \n",
    "            return textdf\n",
    "\n",
    "    def write_dataframe(self,prefix=\"\"):\n",
    "        textdf = pd.DataFrame({\"DocId\": self.listDocId, \"DocEltType\": self.listType, \"DocEltCmd\" : self.listCmd, \"NestingLevel\": self.listLevel, \"Text\":self.listText})\n",
    "        textdf = textdf.astype({\"DocEltType\": \"category\", \"DocEltCmd\": \"category\", \"NestingLevel\": np.uint8},copy=False)\n",
    "        textdffile = self.path / (prefix + \"nlptextdocs.dataframe.feather\")\n",
    "        textdf.to_feather(textdffile)\n",
    "        self.__init__(self.path)\n",
    "        return textdf\n",
    "        \n",
    "    def readline(self,line):\n",
    "        self.onTextBlock(line)\n",
    "        \n",
    "    def onDocumentStart(self,docId):\n",
    "        self.appendrow(\"Document\",\"Start\",docId)\n",
    "    \n",
    "    def onDocumentTitle(self,title):\n",
    "        self.appendrow(\"Document\",\"Title\",title)\n",
    "            \n",
    "    def onDocumentUri(self,uri):\n",
    "        self.appendrow(\"Document\",\"Uri\",uri)\n",
    "    \n",
    "    def onDocumentEnd(self,docId):\n",
    "        self.appendrow(\"Document\",\"End\",docId)\n",
    "    \n",
    "    def onTextBlock(self,text):\n",
    "        self.appendrow(\"TextBlock\",\"Text\",text)  \n",
    "            \n",
    "    def appendrow(self,docEltType,docEltCmd,text=None):\n",
    "        self.listDocId.append(self.documentCount)\n",
    "        self.listType.append(docEltType)\n",
    "        self.listCmd.append(docEltCmd)\n",
    "        self.listLevel.append(self.nestingLevel)\n",
    "        if(text != None):\n",
    "            text = text.replace(\"\\\\n\",\"\\n\")\n",
    "        self.listText.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000 articles\r"
     ]
    }
   ],
   "source": [
    "wikireader = WikipediaDocsReader(path)\n",
    "textdf = wikireader.load_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocId</th>\n",
       "      <th>DocEltType</th>\n",
       "      <th>DocEltCmd</th>\n",
       "      <th>NestingLevel</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>Start</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>Uri</td>\n",
       "      <td>1</td>\n",
       "      <td>1000_bornes.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>1000 bornes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Les 1000 bornes est un jeu de société utilisan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Sur les premières boîtes du jeu, il était sous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Depuis 2009, la fabrication se fait à l'usine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le jeu comprend 106 cartes. Les deux joueurs d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>La liberté du joueur est surtout dans la décis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Les images de cartes suivantes sont celles de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Les distances parcourues sont associées à des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le jeu comporte 106 cartes :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Depuis 1954, outre les rééditions du jeu stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Document</td>\n",
       "      <td>End</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>Start</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>Uri</td>\n",
       "      <td>1</td>\n",
       "      <td>1000_De_La_Gaucheti_re.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>1000 De La Gaucheti re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le 1000 De La Gauchetière est le plus haut gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>La tour a été dessiné par Lemay &amp; Associés et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le 1000 de la Gauchetière a été construit par ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Au moment de sa construction, le 1000 de la Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Ce lieu est relié au Montréal souterrain (le R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Sa forme caractéristique en flèche domine et d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Exemple d'architecture post-moderne fortement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le premier étage comporte une patinoire intéri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Document</td>\n",
       "      <td>End</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>Document</td>\n",
       "      <td>Start</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Document</td>\n",
       "      <td>Uri</td>\n",
       "      <td>1</td>\n",
       "      <td>100e_r_giment_d_infanterie.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>Document</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>100e r giment d infanterie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le d'infanterie ( RI) est un régiment d'infant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Colonels tués et blessés à la tête du :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Officiers tués et blessés durant leur service ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1849 : prise de Rome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Le décret du 24 octobre 1854 réorganise les ré...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1881-1888 : le régiment est Algérie&lt;br&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1881 : le fait la campagne de Tunisie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>1907 : en garnison à Narbonne durant la révolt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Affectation : casernement Tulle, DI, DI, d'armée.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Bataille de Vitry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Verdun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Seconde bataille de la Marne en 1918.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Formé le par le CMI 12 (Centre Mobilisateur d'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Régiment de réserve, dérivé du Régiment d'Infa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>le régiment est dissous en 1998.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Il porte, cousues en lettres d'or dans ses pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Sa cravate est décorée de la Croix de guerre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Il a le droit au port de la fourragère aux co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Survivance, cette cravate portait aussi la méd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>\"N'a peur de rien et comme Cambronne il le dit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Pro Rege et Patria!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>TextBlock</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>Nous sommes tous grenadiers!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DocId DocEltType DocEltCmd  NestingLevel  \\\n",
       "0       1   Document     Start             1   \n",
       "1       1   Document       Uri             1   \n",
       "2       1   Document     Title             1   \n",
       "3       1  TextBlock      Text             1   \n",
       "4       1  TextBlock      Text             1   \n",
       "5       1  TextBlock      Text             1   \n",
       "6       1  TextBlock      Text             1   \n",
       "7       1  TextBlock      Text             1   \n",
       "8       1  TextBlock      Text             1   \n",
       "9       1  TextBlock      Text             1   \n",
       "10      1  TextBlock      Text             1   \n",
       "11      1  TextBlock      Text             1   \n",
       "12      1   Document       End             1   \n",
       "13      2   Document     Start             1   \n",
       "14      2   Document       Uri             1   \n",
       "15      2   Document     Title             1   \n",
       "16      2  TextBlock      Text             1   \n",
       "17      2  TextBlock      Text             1   \n",
       "18      2  TextBlock      Text             1   \n",
       "19      2  TextBlock      Text             1   \n",
       "20      2  TextBlock      Text             1   \n",
       "21      2  TextBlock      Text             1   \n",
       "22      2  TextBlock      Text             1   \n",
       "23      2  TextBlock      Text             1   \n",
       "24      2   Document       End             1   \n",
       "25      3   Document     Start             1   \n",
       "26      3   Document       Uri             1   \n",
       "27      3   Document     Title             1   \n",
       "28      3  TextBlock      Text             1   \n",
       "29      3  TextBlock      Text             1   \n",
       "30      3  TextBlock      Text             1   \n",
       "31      3  TextBlock      Text             1   \n",
       "32      3  TextBlock      Text             1   \n",
       "33      3  TextBlock      Text             1   \n",
       "34      3  TextBlock      Text             1   \n",
       "35      3  TextBlock      Text             1   \n",
       "36      3  TextBlock      Text             1   \n",
       "37      3  TextBlock      Text             1   \n",
       "38      3  TextBlock      Text             1   \n",
       "39      3  TextBlock      Text             1   \n",
       "40      3  TextBlock      Text             1   \n",
       "41      3  TextBlock      Text             1   \n",
       "42      3  TextBlock      Text             1   \n",
       "43      3  TextBlock      Text             1   \n",
       "44      3  TextBlock      Text             1   \n",
       "45      3  TextBlock      Text             1   \n",
       "46      3  TextBlock      Text             1   \n",
       "47      3  TextBlock      Text             1   \n",
       "48      3  TextBlock      Text             1   \n",
       "49      3  TextBlock      Text             1   \n",
       "\n",
       "                                                 Text  \n",
       "0                                                   1  \n",
       "1                                     1000_bornes.txt  \n",
       "2                                         1000 bornes  \n",
       "3   Les 1000 bornes est un jeu de société utilisan...  \n",
       "4   Sur les premières boîtes du jeu, il était sous...  \n",
       "5   Depuis 2009, la fabrication se fait à l'usine ...  \n",
       "6   Le jeu comprend 106 cartes. Les deux joueurs d...  \n",
       "7   La liberté du joueur est surtout dans la décis...  \n",
       "8   Les images de cartes suivantes sont celles de ...  \n",
       "9   Les distances parcourues sont associées à des ...  \n",
       "10                       Le jeu comporte 106 cartes :  \n",
       "11  Depuis 1954, outre les rééditions du jeu stand...  \n",
       "12                                                  1  \n",
       "13                                                  2  \n",
       "14                         1000_De_La_Gaucheti_re.txt  \n",
       "15                             1000 De La Gaucheti re  \n",
       "16  Le 1000 De La Gauchetière est le plus haut gra...  \n",
       "17  La tour a été dessiné par Lemay & Associés et ...  \n",
       "18  Le 1000 de la Gauchetière a été construit par ...  \n",
       "19  Au moment de sa construction, le 1000 de la Ga...  \n",
       "20  Ce lieu est relié au Montréal souterrain (le R...  \n",
       "21  Sa forme caractéristique en flèche domine et d...  \n",
       "22  Exemple d'architecture post-moderne fortement ...  \n",
       "23  Le premier étage comporte une patinoire intéri...  \n",
       "24                                                  2  \n",
       "25                                                  3  \n",
       "26                     100e_r_giment_d_infanterie.txt  \n",
       "27                         100e r giment d infanterie  \n",
       "28  Le d'infanterie ( RI) est un régiment d'infant...  \n",
       "29            Colonels tués et blessés à la tête du :  \n",
       "30  Officiers tués et blessés durant leur service ...  \n",
       "31                               1849 : prise de Rome  \n",
       "32  Le décret du 24 octobre 1854 réorganise les ré...  \n",
       "33            1881-1888 : le régiment est Algérie<br>  \n",
       "34              1881 : le fait la campagne de Tunisie  \n",
       "35  1907 : en garnison à Narbonne durant la révolt...  \n",
       "36  Affectation : casernement Tulle, DI, DI, d'armée.  \n",
       "37                                  Bataille de Vitry  \n",
       "38                                             Verdun  \n",
       "39              Seconde bataille de la Marne en 1918.  \n",
       "40  Formé le par le CMI 12 (Centre Mobilisateur d'...  \n",
       "41  Régiment de réserve, dérivé du Régiment d'Infa...  \n",
       "42                   le régiment est dissous en 1998.  \n",
       "43  \"Il porte, cousues en lettres d'or dans ses pl...  \n",
       "44  \"Sa cravate est décorée de la Croix de guerre ...  \n",
       "45  \"Il a le droit au port de la fourragère aux co...  \n",
       "46  Survivance, cette cravate portait aussi la méd...  \n",
       "47  \"N'a peur de rien et comme Cambronne il le dit...  \n",
       "48                                Pro Rege et Patria!  \n",
       "49                       Nous sommes tous grenadiers!  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "rootdir = Path(r\"\\\\?\\D:\\Laurent\\nlptextdoc-data-201909\")\n",
    "\n",
    "websites = []\n",
    "\n",
    "SCOPE_KEY = \"scope=\"\n",
    "URL_KEY=\"rootUrl=\"\n",
    "\n",
    "for entry in os.scandir(rootdir):\n",
    "    if entry.is_dir():\n",
    "        websitedir = Path(entry)\n",
    "        if(not websitedir.name.startswith(\"wikipedia-\")):\n",
    "            continue\n",
    "        configfile = websitedir / \"_nlptextdoc\" / \"config.txt\"\n",
    "        scope = \"\"\n",
    "        if configfile.exists():\n",
    "            with configfile.open(mode=\"r\", encoding=\"utf-8-sig\") as f:   \n",
    "                for lineidx,line in enumerate(f):\n",
    "                    line = line.strip()\n",
    "                    if (line.startswith(SCOPE_KEY)):\n",
    "                        scope = line[len(SCOPE_KEY):]\n",
    "                    if (line.startswith(URL_KEY)):\n",
    "                        url = line[len(URL_KEY):]\n",
    "                        websites.append((scope,url,websitedir))\n",
    "                        break\n",
    "                \n",
    "websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "websitedir = websites[0][2]\n",
    "textdffile = websitedir / \"_nlptextdoc\" / \"nlptextdocs.dataframe.feather\"\n",
    "textdf = pd.read_feather(textdffile)\n",
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_urls_dataframe(websitedir):\n",
    "    urlsdffile = websitedir / \"_nlptextdoc\" / \"urls.dataframe.feather\" \n",
    "    if(urlsdffile.exists()):\n",
    "            return pd.read_feather(urlsdffile)\n",
    "    else:\n",
    "        listDocUrls = []\n",
    "        textdffile = websitedir / \"_nlptextdoc\" / \"nlptextdocs.dataframe.feather\"\n",
    "        textdf = pd.read_feather(textdffile)\n",
    "        for rowidx,row in textdf[textdf[\"DocEltCmd\"] == \"Uri\"].iterrows():\n",
    "            article = Path(row[\"Text\"]).stem\n",
    "            listDocUrls.append(\"https://fr.wikipedia.org/wiki/\"+article)\n",
    "        urlsdf = pd.DataFrame({\"DocId\" : range(1,len(listDocUrls)+1), \"DocUrl\" : listDocUrls})\n",
    "        urlsdf = urlsdf.astype({\"DocId\" : np.uint32},copy=False)\n",
    "        urlsdf.to_feather(urlsdffile)     \n",
    "        return urlsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsdf = gen_urls_dataframe(websites[5][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
